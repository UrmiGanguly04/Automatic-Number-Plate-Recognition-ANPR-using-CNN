{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c652ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\URMI GANGULY\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Enter training data path: C:\\Users\\URMI GANGULY\\Documents\\IITG\\Automatic Number Plate Detection\\data\\data\\train\n",
      "Enter validation data path: C:\\Users\\URMI GANGULY\\Documents\\IITG\\Automatic Number Plate Detection\\data\\data\\val\n",
      "Found 864 images belonging to 36 classes.\n",
      "Found 216 images belonging to 36 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\URMI GANGULY\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\URMI GANGULY\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\URMI GANGULY\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 24, 24, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 11, 11, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 7744)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               991360    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 36)                4644      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1014820 (3.87 MB)\n",
      "Trainable params: 1014820 (3.87 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\URMI GANGULY\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\URMI GANGULY\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "27/27 [==============================] - 9s 295ms/step - loss: 2.9190 - accuracy: 0.2257 - val_loss: 1.4671 - val_accuracy: 0.7407\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 1.1989 - accuracy: 0.6620 - val_loss: 0.3576 - val_accuracy: 0.9491\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.5465 - accuracy: 0.8333 - val_loss: 0.1593 - val_accuracy: 0.9491\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.3814 - accuracy: 0.8773 - val_loss: 0.1373 - val_accuracy: 0.9630\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.2808 - accuracy: 0.9074 - val_loss: 0.1064 - val_accuracy: 0.9537\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2365 - accuracy: 0.9167 - val_loss: 0.0851 - val_accuracy: 0.9722\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 0.2168 - accuracy: 0.9248 - val_loss: 0.0449 - val_accuracy: 0.9815\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.1972 - accuracy: 0.9329 - val_loss: 0.0784 - val_accuracy: 0.9537\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.1497 - accuracy: 0.9433 - val_loss: 0.0824 - val_accuracy: 0.9630\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.1221 - accuracy: 0.9595 - val_loss: 0.0249 - val_accuracy: 0.9907\n",
      "Enter path to a test image: \"C:\\Users\\URMI GANGULY\\Documents\\IITG\\Automatic Number Plate Detection\\car.jpg\"\n"
     ]
    }
   ],
   "source": [
    "# Automatic Number Plate Recognition (ANPR) using CNN\n",
    "# Author: Urmi Ganguly\n",
    "# Description: This script performs number plate recognition using OpenCV and a custom CNN.\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------------\n",
    "# TensorFlow Import with Error Handling\n",
    "# -------------------------------\n",
    "try:\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    from tensorflow.keras.models import load_model\n",
    "    from tensorflow.keras.preprocessing.image import img_to_array\n",
    "except ImportError as e:\n",
    "    print(\"TensorFlow is not installed or not configured correctly.\")\n",
    "    print(\"Error:\", e)\n",
    "    print(\"Please ensure TensorFlow is installed and compatible with your Python version.\")\n",
    "    exit(1)\n",
    "\n",
    "# -------------------------------\n",
    "# 1. User Input for Paths\n",
    "# -------------------------------\n",
    "try:\n",
    "    train_dir = input(\"Enter training data path: \").strip().strip('\"').strip(\"'\")\n",
    "    val_dir = input(\"Enter validation data path: \").strip().strip('\"').strip(\"'\")\n",
    "except Exception as e:\n",
    "    print(\"Error reading input paths:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Image Generators\n",
    "# -------------------------------\n",
    "img_width, img_height = 50, 50\n",
    "batch_size = 32\n",
    "\n",
    "try:\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "except Exception as e:\n",
    "    print(\"Error loading image data:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. CNN Model\n",
    "# -------------------------------\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Model Training\n",
    "# -------------------------------\n",
    "epochs = 10\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=epochs)\n",
    "model.save(\"character_recognition_cnn.keras\", save_format=\"keras\")\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Plate Detection\n",
    "# -------------------------------\n",
    "def detect_plate(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    filtered = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "    edged = cv2.Canny(filtered, 30, 200)\n",
    "    contours, _ = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "\n",
    "    for c in contours:\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.018 * peri, True)\n",
    "        if len(approx) == 4:\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            plate = image[y:y+h, x:x+w]\n",
    "            cv2.imshow(\"Detected Plate\", plate)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            return plate\n",
    "    return None\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Character Segmentation\n",
    "# -------------------------------\n",
    "def segment_characters(plate_img):\n",
    "    gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "   \n",
    "    characters = []\n",
    "    for i, cnt in enumerate(sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[0])):\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if h / plate_img.shape[0] >= 0.5 and w / plate_img.shape[1] <= 0.5:\n",
    "            char = thresh[y:y+h, x:x+w]\n",
    "            resized = cv2.resize(char, (img_width, img_height))\n",
    "            characters.append(resized)\n",
    "\n",
    "            # Debug display\n",
    "            cv2.imshow(f\"Character {i+1}\", resized)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "    return characters\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Character Recognition\n",
    "# -------------------------------\n",
    "def recognize_characters(characters, model, class_labels):\n",
    "    result = \"\"\n",
    "    for char in characters:\n",
    "        char = char.astype(\"float32\") / 255.0\n",
    "        char = np.expand_dims(char, axis=-1)\n",
    "        char = np.expand_dims(char, axis=0)\n",
    "        pred = model.predict(char, verbose=0)\n",
    "        label = class_labels[np.argmax(pred)]\n",
    "        result += label\n",
    "    return result\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Predict Plate Number\n",
    "# -------------------------------\n",
    "def predict_plate_number(image_path, model, class_indices):\n",
    "    plate_img = detect_plate(image_path)\n",
    "    if plate_img is not None:\n",
    "        chars = segment_characters(plate_img)\n",
    "        labels_map = {v: k.split(\"_\")[1] for k, v in class_indices.items()}\n",
    "        return recognize_characters(chars, model, labels_map)\n",
    "    else:\n",
    "        return \"Plate not detected\"\n",
    "\n",
    "# -------------------------------\n",
    "# 9. User Testing\n",
    "# -------------------------------\n",
    "test_image_path = input(\"Enter path to a test image: \").strip().strip('\"').strip(\"'\")\n",
    "\n",
    "if os.path.exists(test_image_path):\n",
    "    model = load_model(\"character_recognition_cnn.keras\")\n",
    "    predicted_plate = predict_plate_number(test_image_path, model, train_generator.class_indices)\n",
    "    print(\"Detected Plate Number:\", predicted_plate)\n",
    "\n",
    "else:\n",
    "    print(\"Test image path is invalid or does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb75142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b4443d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f991b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a814a979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
